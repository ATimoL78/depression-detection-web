import { useState, useRef, useEffect } from "react";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import { Mic, MicOff, Volume2, Loader2, AlertCircle, CheckCircle2, MessageSquare } from "lucide-react";
import { toast } from "sonner";
import { Progress } from "@/components/ui/progress";

interface VoiceAnalysisResult {
  transcript: string;
  sentiment: string;
  tone: string;
  speechRate: number;
  pauseFrequency: number;
  emotionalIntensity: number;
  depressionRisk: number;
  keyIndicators: string[];
}

interface ConversationTurn {
  role: "interviewer" | "user";
  text: string;
  timestamp: Date;
  analysis?: VoiceAnalysisResult;
}

export default function VoiceInterviewEnhanced() {
  const [isRecording, setIsRecording] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [conversation, setConversation] = useState<ConversationTurn[]>([]);
  const [currentQuestion, setCurrentQuestion] = useState(0);
  const [overallRisk, setOverallRisk] = useState(0);
  const [isProcessing, setIsProcessing] = useState(false);
  
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const recognitionRef = useRef<any>(null);
  const synthRef = useRef<SpeechSynthesis | null>(null);

  // æŠ‘éƒç—‡ç­›æŸ¥é—®é¢˜åˆ—è¡¨
  const interviewQuestions = [
    "ä½ å¥½!æˆ‘æ˜¯AIå¿ƒç†è®¿è°ˆåŠ©æ‰‹ã€‚ä»Šå¤©æ„Ÿè§‰æ€ä¹ˆæ ·?",
    "æœ€è¿‘ä¸€å‘¨,ä½ çš„ç¡çœ è´¨é‡å¦‚ä½•?æœ‰å¤±çœ æˆ–å—œç¡çš„æƒ…å†µå—?",
    "ä½ å¯¹å¹³æ—¶å–œæ¬¢çš„æ´»åŠ¨è¿˜æœ‰å…´è¶£å—?æ¯”å¦‚è¿åŠ¨ã€çœ‹ä¹¦ã€ç¤¾äº¤ç­‰?",
    "æœ€è¿‘æœ‰æ²¡æœ‰æ„Ÿåˆ°ç‰¹åˆ«ç–²åŠ³æˆ–ç²¾åŠ›ä¸è¶³?",
    "ä½ å¯¹è‡ªå·±çš„è¯„ä»·å¦‚ä½•?æœ‰æ²¡æœ‰è§‰å¾—è‡ªå·±æ²¡æœ‰ä»·å€¼æˆ–è‡ªè´£çš„æ—¶å€™?",
    "æ³¨æ„åŠ›å’Œä¸“æ³¨åŠ›æ–¹é¢æœ‰ä»€ä¹ˆå˜åŒ–å—?",
    "é£Ÿæ¬²æœ‰æ²¡æœ‰æ˜æ˜¾çš„æ”¹å˜?ä½“é‡æœ‰å¢åŠ æˆ–å‡å°‘å—?",
    "æœ‰æ²¡æœ‰è§‰å¾—åšäº‹æƒ…çš„é€Ÿåº¦å˜æ…¢äº†,æˆ–è€…åè€Œå˜å¾—å¾ˆç„¦èº?",
    "æœ‰æ²¡æœ‰æƒ³è¿‡ä¼¤å®³è‡ªå·±æˆ–è§‰å¾—æ´»ç€æ²¡æœ‰æ„ä¹‰?",
    "æ„Ÿè°¢ä½ çš„é…åˆ!æˆ‘ä¼šæ ¹æ®ä½ çš„å›ç­”ç»™å‡ºä¸€ä¸ªåˆæ­¥è¯„ä¼°ã€‚"
  ];

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«å’Œåˆæˆ
  useEffect(() => {
    // åˆå§‹åŒ–Web Speech API
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
      const recognition = new SpeechRecognition();
      recognition.lang = 'zh-CN';
      recognition.continuous = false;
      recognition.interimResults = false;

      recognition.onresult = (event: any) => {
        const transcript = event.results[0][0].transcript;
        handleUserResponse(transcript);
      };

      recognition.onerror = (event: any) => {
        console.error('Speech recognition error:', event.error);
        toast.error('è¯­éŸ³è¯†åˆ«å¤±è´¥,è¯·é‡è¯•');
        setIsRecording(false);
      };

      recognitionRef.current = recognition;
    }

    // åˆå§‹åŒ–è¯­éŸ³åˆæˆ
    if ('speechSynthesis' in window) {
      synthRef.current = window.speechSynthesis;
    }

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
      if (synthRef.current) {
        synthRef.current.cancel();
      }
    };
  }, []);

  // å¼€å§‹è®¿è°ˆ
  const startInterview = () => {
    if (!recognitionRef.current || !synthRef.current) {
      toast.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åŠŸèƒ½,è¯·ä½¿ç”¨Chromeæµè§ˆå™¨');
      return;
    }

    setConversation([]);
    setCurrentQuestion(0);
    setOverallRisk(0);
    askQuestion(0);
  };

  // æé—®
  const askQuestion = (questionIndex: number) => {
    if (questionIndex >= interviewQuestions.length) {
      finishInterview();
      return;
    }

    const question = interviewQuestions[questionIndex];
    
    // æ·»åŠ åˆ°å¯¹è¯å†å²
    const turn: ConversationTurn = {
      role: "interviewer",
      text: question,
      timestamp: new Date(),
    };
    setConversation(prev => [...prev, turn]);

    // è¯­éŸ³æ’­æŠ¥é—®é¢˜
    speakText(question);
  };

  // è¯­éŸ³æ’­æŠ¥
  const speakText = (text: string) => {
    if (!synthRef.current) return;

    setIsSpeaking(true);
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'zh-CN';
    utterance.rate = 0.9; // ç¨æ…¢çš„è¯­é€Ÿ,æ›´æ¸©å’Œ
    utterance.pitch = 1.0;
    utterance.volume = 1.0;

    utterance.onend = () => {
      setIsSpeaking(false);
      // æ’­æŠ¥å®Œæˆåè‡ªåŠ¨å¼€å§‹å½•éŸ³
      if (currentQuestion < interviewQuestions.length - 1) {
        setTimeout(() => startRecording(), 500);
      }
    };

    utterance.onerror = () => {
      setIsSpeaking(false);
      toast.error('è¯­éŸ³æ’­æŠ¥å¤±è´¥');
    };

    synthRef.current.speak(utterance);
  };

  // å¼€å§‹å½•éŸ³
  const startRecording = () => {
    if (!recognitionRef.current) {
      toast.error('è¯­éŸ³è¯†åˆ«ä¸å¯ç”¨');
      return;
    }

    try {
      setIsRecording(true);
      recognitionRef.current.start();
      toast.info('è¯·å¼€å§‹å›ç­”...');
    } catch (error) {
      console.error('Recording error:', error);
      toast.error('å½•éŸ³å¯åŠ¨å¤±è´¥');
      setIsRecording(false);
    }
  };

  // åœæ­¢å½•éŸ³
  const stopRecording = () => {
    if (recognitionRef.current && isRecording) {
      recognitionRef.current.stop();
      setIsRecording(false);
    }
  };

  // å¤„ç†ç”¨æˆ·å›ç­”
  const handleUserResponse = async (transcript: string) => {
    setIsRecording(false);
    setIsProcessing(true);

    // æ·»åŠ ç”¨æˆ·å›ç­”åˆ°å¯¹è¯å†å²
    const userTurn: ConversationTurn = {
      role: "user",
      text: transcript,
      timestamp: new Date(),
    };

    try {
      // åˆ†æè¯­éŸ³å’Œæ–‡æœ¬
      const analysis = await analyzeResponse(transcript);
      userTurn.analysis = analysis;

      setConversation(prev => [...prev, userTurn]);

      // æ›´æ–°æ€»ä½“é£é™©è¯„åˆ†
      updateOverallRisk(analysis.depressionRisk);

      // ç»§ç»­ä¸‹ä¸€ä¸ªé—®é¢˜
      const nextQuestion = currentQuestion + 1;
      setCurrentQuestion(nextQuestion);
      
      setTimeout(() => {
        askQuestion(nextQuestion);
      }, 1000);

    } catch (error) {
      console.error('Analysis error:', error);
      toast.error('åˆ†æå¤±è´¥,è¯·é‡è¯•');
      
      setConversation(prev => [...prev, userTurn]);
      
      const nextQuestion = currentQuestion + 1;
      setCurrentQuestion(nextQuestion);
      askQuestion(nextQuestion);
    } finally {
      setIsProcessing(false);
    }
  };

  // åˆ†æå›ç­”(è¯­æ°”ã€è¯­è°ƒã€å†…å®¹)
  const analyzeResponse = async (transcript: string): Promise<VoiceAnalysisResult> => {
    try {
      const response = await fetch('/api/analyze-voice', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          transcript,
          questionIndex: currentQuestion,
        }),
      });

      if (!response.ok) {
        throw new Error('åˆ†æè¯·æ±‚å¤±è´¥');
      }

      const data = await response.json();
      return data;

    } catch (error) {
      console.error('Voice analysis error:', error);
      
      // é™çº§åˆ°æœ¬åœ°ç®€å•åˆ†æ
      return analyzeResponseLocally(transcript);
    }
  };

  // æœ¬åœ°ç®€å•åˆ†æ(é™çº§æ–¹æ¡ˆ)
  const analyzeResponseLocally = (transcript: string): VoiceAnalysisResult => {
    let risk = 0;
    const indicators: string[] = [];

    // å…³é”®è¯åˆ†æ
    const negativeKeywords = ['ä¸æƒ³', 'æ²¡æœ‰', 'å¤±çœ ', 'ç–²åŠ³', 'æ²¡æ„ä¹‰', 'è‡ªè´£', 'ç—›è‹¦', 'éš¾è¿‡', 'ç»æœ›'];
    const positiveKeywords = ['è¿˜å¥½', 'æ­£å¸¸', 'å¯ä»¥', 'æœ‰', 'å–œæ¬¢', 'å¼€å¿ƒ'];

    negativeKeywords.forEach(keyword => {
      if (transcript.includes(keyword)) {
        risk += 10;
        indicators.push(`è´Ÿé¢è¡¨è¾¾: "${keyword}"`);
      }
    });

    positiveKeywords.forEach(keyword => {
      if (transcript.includes(keyword)) {
        risk -= 5;
      }
    });

    // å›ç­”é•¿åº¦åˆ†æ(è¿‡çŸ­å¯èƒ½è¡¨ç¤ºå…´è¶£ç¼ºå¤±)
    if (transcript.length < 10) {
      risk += 15;
      indicators.push('å›ç­”è¿‡äºç®€çŸ­');
    }

    // æƒ…æ„Ÿå¼ºåº¦(æ ¹æ®æ ‡ç‚¹å’Œè¯­æ°”è¯)
    const emotionalMarkers = transcript.match(/[!?ã€‚,ã€]/g) || [];
    const emotionalIntensity = Math.min(100, emotionalMarkers.length * 20);

    return {
      transcript,
      sentiment: risk > 50 ? 'æ¶ˆæ' : risk > 30 ? 'ä¸­æ€§åæ¶ˆæ' : 'ä¸­æ€§',
      tone: risk > 60 ? 'ä½æ²‰' : 'å¹³ç¨³',
      speechRate: 100, // æ— æ³•ä»æ–‡æœ¬åˆ†æ
      pauseFrequency: 0,
      emotionalIntensity,
      depressionRisk: Math.max(0, Math.min(100, risk)),
      keyIndicators: indicators,
    };
  };

  // æ›´æ–°æ€»ä½“é£é™©è¯„åˆ†
  const updateOverallRisk = (newRisk: number) => {
    setOverallRisk(prev => {
      const count = conversation.filter(c => c.role === 'user').length + 1;
      return Math.round((prev * (count - 1) + newRisk) / count);
    });
  };

  // å®Œæˆè®¿è°ˆ
  const finishInterview = () => {
    const finalMessage = `è®¿è°ˆå®Œæˆ!æ ¹æ®æ‚¨çš„å›ç­”,åˆæ­¥è¯„ä¼°æ‚¨çš„æŠ‘éƒç—‡é£é™©è¯„åˆ†ä¸º ${overallRisk} åˆ†(æ»¡åˆ†100åˆ†)ã€‚`;
    
    let recommendation = "";
    if (overallRisk < 30) {
      recommendation = "æ‚¨çš„æƒ…ç»ªçŠ¶æ€æ€»ä½“è‰¯å¥½,è¯·ç»§ç»­ä¿æŒç§¯æçš„ç”Ÿæ´»æ–¹å¼ã€‚";
    } else if (overallRisk < 60) {
      recommendation = "æ‚¨å¯èƒ½å­˜åœ¨ä¸€å®šçš„æƒ…ç»ªå›°æ‰°,å»ºè®®å…³æ³¨è‡ªå·±çš„å¿ƒç†å¥åº·,å¿…è¦æ—¶å¯»æ±‚ä¸“ä¸šå¸®åŠ©ã€‚";
    } else {
      recommendation = "æ‚¨çš„å›ç­”æ˜¾ç¤ºå¯èƒ½å­˜åœ¨è¾ƒé«˜çš„æŠ‘éƒé£é™©,å¼ºçƒˆå»ºè®®å°½å¿«è”ç³»ä¸“ä¸šå¿ƒç†å’¨è¯¢å¸ˆæˆ–ç²¾ç¥ç§‘åŒ»ç”Ÿã€‚å…¨å›½å¿ƒç†æ´åŠ©çƒ­çº¿: 400-161-9995";
    }

    speakText(finalMessage + recommendation);
    
    toast.success('è®¿è°ˆå®Œæˆ', {
      description: recommendation,
      duration: 10000,
    });
  };

  return (
    <Card className="w-full">
      <CardHeader>
        <CardTitle className="flex items-center gap-2">
          <MessageSquare className="h-5 w-5 text-primary" />
          å®æ—¶è¯­éŸ³é—®ç­”è®¿è°ˆ
        </CardTitle>
        <p className="text-sm text-muted-foreground">
          é€šè¿‡è¯­éŸ³å¯¹è¯åˆ†æè¯­æ°”ã€è¯­è°ƒå’Œè¯´è¯é£æ ¼,è¾…åŠ©è¯„ä¼°æŠ‘éƒç—‡é£é™©
        </p>
      </CardHeader>

      <CardContent className="space-y-6">
        {/* è®¿è°ˆè¿›åº¦ */}
        {conversation.length > 0 && (
          <div className="space-y-2">
            <div className="flex justify-between text-sm">
              <span>è®¿è°ˆè¿›åº¦</span>
              <span>{currentQuestion}/{interviewQuestions.length}</span>
            </div>
            <Progress value={(currentQuestion / interviewQuestions.length) * 100} />
          </div>
        )}

        {/* æ€»ä½“é£é™©è¯„åˆ† */}
        {conversation.length > 0 && (
          <div className="p-4 bg-gradient-to-r from-blue-50 to-purple-50 dark:from-blue-950/20 dark:to-purple-950/20 rounded-lg border">
            <div className="flex items-center justify-between mb-2">
              <span className="font-semibold">å®æ—¶é£é™©è¯„åˆ†</span>
              <span className="text-2xl font-bold text-primary">{overallRisk}/100</span>
            </div>
            <Progress 
              value={overallRisk} 
              className={`h-3 ${
                overallRisk < 30 ? 'bg-green-200' :
                overallRisk < 60 ? 'bg-yellow-200' :
                'bg-red-200'
              }`}
            />
            <p className="text-xs text-muted-foreground mt-2">
              {overallRisk < 30 && "æƒ…ç»ªçŠ¶æ€è‰¯å¥½"}
              {overallRisk >= 30 && overallRisk < 60 && "å­˜åœ¨ä¸€å®šæƒ…ç»ªå›°æ‰°"}
              {overallRisk >= 60 && "å»ºè®®å¯»æ±‚ä¸“ä¸šå¸®åŠ©"}
            </p>
          </div>
        )}

        {/* å¯¹è¯å†å² */}
        <div className="space-y-3 max-h-96 overflow-y-auto">
          {conversation.map((turn, index) => (
            <div
              key={index}
              className={`flex ${turn.role === 'user' ? 'justify-end' : 'justify-start'}`}
            >
              <div
                className={`max-w-[80%] rounded-lg px-4 py-3 ${
                  turn.role === 'interviewer'
                    ? 'bg-primary text-primary-foreground'
                    : 'bg-muted'
                }`}
              >
                <div className="flex items-start gap-2">
                  {turn.role === 'interviewer' ? (
                    <Volume2 className="h-4 w-4 mt-0.5 flex-shrink-0" />
                  ) : (
                    <Mic className="h-4 w-4 mt-0.5 flex-shrink-0" />
                  )}
                  <div className="flex-1">
                    <p className="text-sm">{turn.text}</p>
                    {turn.analysis && (
                      <div className="mt-2 pt-2 border-t border-border/50 text-xs space-y-1">
                        <div className="flex justify-between">
                          <span>æƒ…æ„Ÿå€¾å‘:</span>
                          <span className="font-semibold">{turn.analysis.sentiment}</span>
                        </div>
                        <div className="flex justify-between">
                          <span>è¯­æ°”:</span>
                          <span className="font-semibold">{turn.analysis.tone}</span>
                        </div>
                        <div className="flex justify-between">
                          <span>é£é™©è¯„åˆ†:</span>
                          <span className={`font-semibold ${
                            turn.analysis.depressionRisk > 60 ? 'text-red-500' :
                            turn.analysis.depressionRisk > 30 ? 'text-yellow-500' :
                            'text-green-500'
                          }`}>
                            {turn.analysis.depressionRisk}/100
                          </span>
                        </div>
                        {turn.analysis.keyIndicators.length > 0 && (
                          <div className="mt-1">
                            <span>å…³é”®æŒ‡æ ‡:</span>
                            <ul className="ml-2 mt-1">
                              {turn.analysis.keyIndicators.map((indicator, i) => (
                                <li key={i}>â€¢ {indicator}</li>
                              ))}
                            </ul>
                          </div>
                        )}
                      </div>
                    )}
                  </div>
                </div>
                <p className="text-xs opacity-70 mt-1 text-right">
                  {turn.timestamp.toLocaleTimeString('zh-CN', {
                    hour: '2-digit',
                    minute: '2-digit',
                  })}
                </p>
              </div>
            </div>
          ))}

          {isProcessing && (
            <div className="flex justify-center">
              <div className="bg-muted rounded-lg px-4 py-2 flex items-center gap-2">
                <Loader2 className="h-4 w-4 animate-spin" />
                <span className="text-sm">åˆ†æä¸­...</span>
              </div>
            </div>
          )}
        </div>

        {/* æ§åˆ¶æŒ‰é’® */}
        <div className="flex gap-3">
          {conversation.length === 0 ? (
            <Button
              onClick={startInterview}
              className="flex-1"
              size="lg"
            >
              <Mic className="mr-2 h-5 w-5" />
              å¼€å§‹è¯­éŸ³è®¿è°ˆ
            </Button>
          ) : (
            <>
              {isRecording ? (
                <Button
                  onClick={stopRecording}
                  variant="destructive"
                  className="flex-1"
                  size="lg"
                >
                  <MicOff className="mr-2 h-5 w-5" />
                  åœæ­¢å½•éŸ³
                </Button>
              ) : isSpeaking ? (
                <Button
                  disabled
                  className="flex-1"
                  size="lg"
                >
                  <Volume2 className="mr-2 h-5 w-5 animate-pulse" />
                  AIæ­£åœ¨æé—®...
                </Button>
              ) : currentQuestion < interviewQuestions.length - 1 ? (
                <Button
                  onClick={startRecording}
                  className="flex-1"
                  size="lg"
                >
                  <Mic className="mr-2 h-5 w-5" />
                  å¼€å§‹å›ç­”
                </Button>
              ) : (
                <Button
                  onClick={() => {
                    setConversation([]);
                    setCurrentQuestion(0);
                    setOverallRisk(0);
                  }}
                  variant="outline"
                  className="flex-1"
                  size="lg"
                >
                  é‡æ–°å¼€å§‹è®¿è°ˆ
                </Button>
              )}
            </>
          )}
        </div>

        {/* åŠŸèƒ½è¯´æ˜ */}
        <div className="text-xs text-muted-foreground space-y-1 p-3 bg-muted/30 rounded">
          <div className="font-semibold mb-1">ğŸ™ï¸ è¯­éŸ³è®¿è°ˆç‰¹æ€§:</div>
          <ul className="space-y-0.5 ml-4">
            <li>â€¢ åŸºäºPHQ-9æ ‡å‡†çš„ç»“æ„åŒ–è®¿è°ˆé—®é¢˜</li>
            <li>â€¢ å®æ—¶è¯­éŸ³è¯†åˆ«å’Œè¯­æ°”åˆ†æ</li>
            <li>â€¢ AIè¯­éŸ³æ’­æŠ¥,è‡ªç„¶å¯¹è¯ä½“éªŒ</li>
            <li>â€¢ å¤šç»´åº¦è¯„ä¼°:è¯­æ°”ã€è¯­è°ƒã€è¯´è¯é£æ ¼ã€æƒ…æ„Ÿå€¾å‘</li>
            <li>â€¢ å®æ—¶é£é™©è¯„åˆ†å’Œå…³é”®æŒ‡æ ‡æç¤º</li>
          </ul>
        </div>

        {/* æµè§ˆå™¨å…¼å®¹æ€§æç¤º */}
        {!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) && (
          <div className="flex items-start gap-2 p-3 bg-yellow-50 dark:bg-yellow-950/20 border border-yellow-200 dark:border-yellow-800 rounded-lg">
            <AlertCircle className="h-5 w-5 text-yellow-600 dark:text-yellow-400 flex-shrink-0 mt-0.5" />
            <div className="text-sm text-yellow-800 dark:text-yellow-200">
              <p className="font-semibold">æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³åŠŸèƒ½</p>
              <p className="mt-1">è¯·ä½¿ç”¨Chromeæµè§ˆå™¨ä»¥è·å¾—æœ€ä½³ä½“éªŒ</p>
            </div>
          </div>
        )}
      </CardContent>
    </Card>
  );
}
